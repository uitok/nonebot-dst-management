"""
DST AI æ™ºèƒ½é—®ç­”ç³»ç»Ÿ

åŸºäºé¡¹ç›®æ–‡æ¡£ä¸ DST åŸºç¡€çŸ¥è¯†ç”Ÿæˆé—®ç­”ã€‚
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Sequence

from loguru import logger

from .base import AIError, format_ai_error
from .client import AIClient
from .prompt import TemplateManager, format_history, format_sources
from .session import SessionManager


@dataclass(frozen=True)
class KnowledgeSource:
    """çŸ¥è¯†åº“æ¥æº"""

    name: str
    content: str


class QASystem:
    """AI é—®ç­”ç³»ç»Ÿ"""

    def __init__(
        self,
        ai_client: AIClient,
        docs_root: Optional[Path] = None,
        session_manager: Optional[SessionManager] = None,
        template_manager: Optional[TemplateManager] = None,
    ) -> None:
        self.ai_client = ai_client
        self.docs_root = docs_root or Path(__file__).resolve().parents[2]
        self.session_manager = session_manager or SessionManager(
            max_rounds=ai_client.config.session_max_rounds,
            ttl_seconds=ai_client.config.session_ttl,
        )
        self.template_manager = template_manager or self._build_template_manager()

    async def ask(
        self,
        question: str,
        context: Optional[str] = None,
        session_id: Optional[str] = None,
    ) -> str:
        """
        æ‰§è¡Œé—®ç­”

        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: å¯é€‰ä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ ID

        Returns:
            str: Markdown æ ¼å¼å›ç­”
        """
        sources = self._build_knowledge_base(context)
        history = self.session_manager.list_history(session_id) if session_id else []
        prompt = self._build_prompt(question, sources, history, context)
        system_prompt = self._system_prompt()

        try:
            response = await self.ai_client.chat(
                [{"role": "user", "content": prompt}],
                system_prompt=system_prompt,
            )
            if response and response.strip():
                answer = response.strip()
                if session_id:
                    self.session_manager.append_turn(session_id, question, answer)
                return answer
        except AIError as exc:
            logger.warning("AI é—®ç­”å¤±è´¥ï¼Œå›é€€æœ¬åœ°å›ç­”ï¼š{err}", err=exc)
            return self._fallback_answer(question, sources, exc)
        except Exception as exc:
            logger.exception("AI é—®ç­”å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{err}", err=exc)
            return self._fallback_answer(question, sources, exc)

        return self._fallback_answer(question, sources, None)

    async def ask_stream(
        self,
        question: str,
        context: Optional[str] = None,
        session_id: Optional[str] = None,
    ):
        sources = self._build_knowledge_base(context)
        history = self.session_manager.list_history(session_id) if session_id else []
        prompt = self._build_prompt(question, sources, history, context)
        system_prompt = self._system_prompt()

        response_parts: List[str] = []
        try:
            async for chunk in self.ai_client.stream_chat(
                [{"role": "user", "content": prompt}],
                system_prompt=system_prompt,
            ):
                if chunk:
                    response_parts.append(chunk)
                    yield chunk
        except AIError as exc:
            logger.warning("AI æµå¼é—®ç­”å¤±è´¥ï¼Œå›é€€æœ¬åœ°å›ç­”ï¼š{err}", err=exc)
            yield self._fallback_answer(question, sources, exc)
            return
        except Exception as exc:
            logger.exception("AI æµå¼é—®ç­”å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{err}", err=exc)
            yield self._fallback_answer(question, sources, exc)
            return

        answer = "".join(response_parts).strip()
        if not answer:
            yield self._fallback_answer(question, sources, None)
            return
        if session_id:
            self.session_manager.append_turn(session_id, question, answer)

    def reset_session(self, session_id: str) -> None:
        self.session_manager.reset_session(session_id)

    def _build_knowledge_base(self, extra_context: Optional[str]) -> List[KnowledgeSource]:
        sources: List[KnowledgeSource] = []
        doc_paths = [
            self.docs_root / "README.md",
            self.docs_root / "COMMANDS.md",
            self.docs_root / "AI_COMPLETE_PLAN.md",
        ]

        for path in doc_paths:
            if not path.exists():
                continue
            try:
                content = path.read_text(encoding="utf-8")
            except Exception:
                continue
            if len(content) > 6000:
                content = content[:6000] + "\n..."
            sources.append(KnowledgeSource(name=path.name, content=content))

        sources.append(KnowledgeSource(name="DST basics", content=_DST_BASICS))

        if extra_context:
            sources.append(KnowledgeSource(name="User context", content=extra_context))

        return sources

    def _build_prompt(
        self,
        question: str,
        sources: Sequence[KnowledgeSource],
        history: Sequence[dict[str, str]],
        context: Optional[str],
    ) -> str:
        sources_text = format_sources([(source.name, source.content) for source in sources])
        history_text = format_history(history)
        context_text = f"è¡¥å……ä¸Šä¸‹æ–‡ï¼š\n{context}\n" if context else ""
        variables = {
            "question": question,
            "sources": sources_text,
            "history": history_text,
            "context": context_text,
        }
        return self.template_manager.render(variables)

    def _system_prompt(self) -> str:
        return "ä½ æ˜¯ DST æœåŠ¡å™¨ä¸ç®¡ç†æ’ä»¶ä¸“å®¶ï¼Œå›ç­”æ—¶ä¸¥è°¨ä¸”å¯æ‰§è¡Œã€‚"

    def _fallback_answer(
        self,
        question: str,
        sources: Sequence[KnowledgeSource],
        error: Optional[Exception],
    ) -> str:
        lines = ["ğŸ¤– æ™ºèƒ½é—®ç­”", "", f"é—®é¢˜ï¼š{question}", "", "å½“å‰æ— æ³•è·å¾— AI ç­”å¤ã€‚"]
        lines.append("å¯å‚è€ƒä»¥ä¸‹èµ„æ–™ï¼š")
        for source in sources:
            lines.append(f"- {source.name}")
        if error is not None:
            lines.append("")
            if isinstance(error, AIError):
                lines.append(f"âš ï¸ AI é—®ç­”å¤±è´¥ï¼š{format_ai_error(error)}")
            else:
                lines.append(f"âš ï¸ AI é—®ç­”å¤±è´¥ï¼š{error}")
        return "\n".join(lines)

    def _build_template_manager(self) -> TemplateManager:
        config = self.ai_client.config
        templates = dict(config.prompt_templates)
        if config.prompt_template:
            templates["custom"] = config.prompt_template
        if config.prompt_template and config.prompt_active == "default":
            active = "custom"
        else:
            active = config.prompt_active or ("custom" if config.prompt_template else "default")
        return TemplateManager(templates=templates, active=active)


_DST_BASICS = (
    "DST åŸºç¡€çŸ¥è¯†ï¼š\n"
    "- Master ä¸ºä¸»ä¸–ç•Œï¼ŒCaves ä¸ºæ´ç©´ä¸–ç•Œã€‚\n"
    "- modoverrides.lua ç”¨äºé…ç½®æœåŠ¡å™¨æ¨¡ç»„ã€‚\n"
    "- ä¿®æ”¹é…ç½®åé€šå¸¸éœ€è¦é‡å¯æˆ¿é—´æ‰èƒ½ç”Ÿæ•ˆã€‚\n"
)
