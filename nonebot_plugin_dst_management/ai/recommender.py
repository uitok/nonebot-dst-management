"""
DST æ¨¡ç»„æŽ¨èå™¨

åŸºäºŽå½“å‰æˆ¿é—´æ¨¡ç»„é…ç½®ä¸Žçƒ­é—¨æ¨¡ç»„æ± ï¼Œè°ƒç”¨ AI è¾“å‡ºæŽ¨èæŠ¥å‘Šã€‚
"""

from __future__ import annotations

import json
import time
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

from loguru import logger

from .base import AIError, format_ai_error
from .client import AIClient
from ..client.api_client import DSTApiClient


@dataclass(frozen=True)
class ModCandidate:
    """å€™é€‰æ¨¡ç»„ç»“æž„"""

    mod_id: str
    name: str
    mod_type: str
    tags: Tuple[str, ...] = ()


@dataclass(frozen=True)
class ModRecommendation:
    """æŽ¨èç»“æžœç»“æž„"""

    mod_id: str
    name: str
    score: float
    reason: str


class ModRecommender:
    """
    æ¨¡ç»„æŽ¨èå™¨

    Attributes:
        api_client: DMP API å®¢æˆ·ç«¯
        ai_client: AI å®¢æˆ·ç«¯
    """

    _cache: Dict[str, Tuple[float, Dict[str, Any]]]

    def __init__(self, api_client: DSTApiClient, ai_client: AIClient) -> None:
        self.api_client = api_client
        self.ai_client = ai_client
        self._cache = {}

    async def recommend_mods(self, room_id: int, mod_type: Optional[str] = None) -> Dict[str, Any]:
        """
        æŽ¨èæ¨¡ç»„å¹¶ç”Ÿæˆ Markdown æŠ¥å‘Š

        Args:
            room_id: æˆ¿é—´ ID
            mod_type: æ¨¡ç»„ç±»åž‹ï¼ˆå¯é€‰ï¼‰

        Returns:
            Dict[str, Any]: {
                "report": str,
                "recommendations": List[Dict[str, Any]],
                "cached": bool,
            }
        """
        cache_key = f"{room_id}:{(mod_type or '').lower()}"
        cached = self._get_cached(cache_key, ttl=86400)
        if cached is not None:
            return {**cached, "cached": True}

        mods_result = await self.api_client.get_room_mods(room_id)
        if not mods_result.get("success"):
            error = mods_result.get("error") or "æœªçŸ¥é”™è¯¯"
            raise RuntimeError(f"èŽ·å–æˆ¿é—´æ¨¡ç»„å¤±è´¥ï¼š{error}")

        mods_data = mods_result.get("data") or {}
        installed = set((mods_data.get("enabled") or []) + (mods_data.get("disabled") or []))
        duplicates = mods_data.get("duplicates") or []

        candidates = await self._get_top_mods()
        filtered, filtered_reason = self._filter_candidates(candidates, installed, mod_type)

        prompt = self._build_prompt(room_id, mod_type, installed, filtered)
        system_prompt = self._system_prompt()

        try:
            response = await self.ai_client.chat(
                [{"role": "user", "content": prompt}],
                system_prompt=system_prompt,
            )
            recommendations = self._parse_ai_response(response, filtered)
        except AIError as exc:
            logger.warning("AI æ¨¡ç»„æŽ¨èå¤±è´¥ï¼Œå›žé€€æœ¬åœ°æŽ¨èï¼š{err}", err=exc)
            recommendations = self._fallback_recommendations(filtered)
            report = self._build_report(
                room_id,
                mod_type,
                installed,
                duplicates,
                recommendations,
                filtered_reason,
                ai_error=exc,
            )
            result = {"report": report, "recommendations": recommendations}
            self._set_cached(cache_key, result)
            return {**result, "cached": False}
        except Exception as exc:
            logger.exception("æ¨¡ç»„æŽ¨èå‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{err}", err=exc)
            recommendations = self._fallback_recommendations(filtered)
            report = self._build_report(
                room_id,
                mod_type,
                installed,
                duplicates,
                recommendations,
                filtered_reason,
                ai_error=exc,
            )
            result = {"report": report, "recommendations": recommendations}
            self._set_cached(cache_key, result)
            return {**result, "cached": False}

        report = self._build_report(
            room_id,
            mod_type,
            installed,
            duplicates,
            recommendations,
            filtered_reason,
            ai_error=None,
        )
        result = {"report": report, "recommendations": recommendations}
        self._set_cached(cache_key, result)
        return {**result, "cached": False}

    async def _get_top_mods(self) -> List[ModCandidate]:
        """èŽ·å–çƒ­é—¨æ¨¡ç»„æ± ï¼ˆTop 50ï¼‰ã€‚"""
        if hasattr(self.api_client, "search_mod"):
            try:
                result = await self.api_client.search_mod("hot", "50")  # type: ignore[attr-defined]
                if result.get("success"):
                    return self._convert_search_results(result.get("data") or [])
            except Exception as exc:
                logger.warning("çƒ­é—¨æ¨¡ç»„æ‹‰å–å¤±è´¥ï¼Œä½¿ç”¨å†…ç½®æ± ï¼š{err}", err=exc)
        return list(_DEFAULT_MOD_POOL)

    def _convert_search_results(self, data: List[Dict[str, Any]]) -> List[ModCandidate]:
        candidates: List[ModCandidate] = []
        for item in data:
            mod_id = item.get("id") or item.get("modId") or item.get("mod_id")
            name = item.get("name") or item.get("title") or "Unknown Mod"
            mod_type = item.get("type") or item.get("category") or "functional"
            if not mod_id:
                continue
            mod_id_str = str(mod_id)
            if not mod_id_str.startswith("workshop-"):
                mod_id_str = f"workshop-{mod_id_str}"
            candidates.append(ModCandidate(mod_id_str, str(name), str(mod_type), ()))
        if candidates:
            return candidates[:50]
        return list(_DEFAULT_MOD_POOL)

    def _filter_candidates(
        self,
        candidates: List[ModCandidate],
        installed: set[str],
        mod_type: Optional[str],
    ) -> Tuple[List[ModCandidate], str]:
        """è¿‡æ»¤å·²å®‰è£…ä¸Žå†²çªæ¨¡ç»„ï¼Œå¹¶æŒ‰ç±»åž‹ç­›é€‰ã€‚"""
        mod_type_norm = mod_type.lower().strip() if mod_type else ""
        filtered: List[ModCandidate] = []
        filtered_out = 0

        for mod in candidates:
            if mod.mod_id in installed:
                filtered_out += 1
                continue
            conflicts = _CONFLICT_MAP.get(mod.mod_id, set())
            if conflicts.intersection(installed):
                filtered_out += 1
                continue
            if mod_type_norm and mod.mod_type.lower() != mod_type_norm:
                continue
            filtered.append(mod)

        reason = f"å·²è¿‡æ»¤ {filtered_out} ä¸ªå·²å®‰è£…/å†²çªæ¨¡ç»„"
        return filtered, reason

    def _build_prompt(
        self,
        room_id: int,
        mod_type: Optional[str],
        installed: set[str],
        candidates: List[ModCandidate],
    ) -> str:
        payload = {
            "room_id": room_id,
            "mod_type": mod_type or "all",
            "installed_mods": sorted(installed),
            "candidates": [
                {
                    "id": mod.mod_id,
                    "name": mod.name,
                    "type": mod.mod_type,
                    "tags": list(mod.tags),
                }
                for mod in candidates
            ],
        }

        return (
            "ä½ æ˜¯ DST æ¨¡ç»„æŽ¨èä¸“å®¶ï¼Œè¯·æ ¹æ®å€™é€‰æ¨¡ç»„æ± å’Œå½“å‰å·²å®‰è£…æ¨¡ç»„ï¼ŒæŽ¨èæœ€é€‚åˆçš„ 5 ä¸ªæ¨¡ç»„ã€‚\n\n"
            f"è¾“å…¥æ•°æ®(JSON)ï¼š\n{json.dumps(payload, ensure_ascii=True, indent=2)}\n\n"
            "è¦æ±‚ï¼š\n"
            "1. è¾“å‡º JSON æ ¼å¼ï¼Œé”®åä¸º recommendationsã€‚\n"
            "2. recommendations ä¸ºæ•°ç»„ï¼Œæ¯é¡¹åŒ…å« mod_id, name, score(1-10), reasonã€‚\n"
            "3. æŽ¨èåº”é¿å…ä¸Žå·²å®‰è£…æ¨¡ç»„å†²çªã€‚\n"
            "4. åªè¿”å›ž 5 ä¸ªæŽ¨èã€‚\n"
        )

    def _system_prompt(self) -> str:
        return "ä½ æ˜¯ DST æœåŠ¡å™¨æ¨¡ç»„ä¸“å®¶ï¼Œæ“…é•¿åˆ†æžæ¨¡ç»„å…¼å®¹æ€§ä¸ŽçŽ©æ³•éœ€æ±‚ã€‚"

    def _parse_ai_response(self, response: str, candidates: List[ModCandidate]) -> List[Dict[str, Any]]:
        data = self._extract_json(response)
        if not isinstance(data, dict):
            raise ValueError("AI å“åº”ä¸æ˜¯ JSON å¯¹è±¡")
        items = data.get("recommendations")
        if not isinstance(items, list):
            raise ValueError("AI å“åº”ç¼ºå°‘ recommendations")

        candidate_map = {mod.mod_id: mod for mod in candidates}
        recommendations: List[Dict[str, Any]] = []
        for item in items[:5]:
            if not isinstance(item, dict):
                continue
            mod_id = str(item.get("mod_id") or item.get("id") or "").strip()
            if not mod_id:
                continue
            if not mod_id.startswith("workshop-"):
                mod_id = f"workshop-{mod_id}"
            name = str(item.get("name") or candidate_map.get(mod_id, ModCandidate(mod_id, mod_id, "")).name)
            score = float(item.get("score") or 8.0)
            reason = str(item.get("reason") or "æŽ¨è")
            recommendations.append(
                {
                    "mod_id": mod_id,
                    "name": name,
                    "score": score,
                    "reason": reason,
                }
            )

        if not recommendations:
            raise ValueError("AI æŽ¨èç»“æžœä¸ºç©º")
        return recommendations[:5]

    def _fallback_recommendations(self, candidates: List[ModCandidate]) -> List[Dict[str, Any]]:
        recommendations: List[Dict[str, Any]] = []
        for idx, mod in enumerate(candidates[:5], 1):
            recommendations.append(
                {
                    "mod_id": mod.mod_id,
                    "name": mod.name,
                    "score": round(9.5 - idx * 0.3, 1),
                    "reason": "åŸºäºŽçƒ­é—¨åº¦ä¸Žå…¼å®¹æ€§è¿›è¡Œæœ¬åœ°æŽ¨è",
                }
            )
        return recommendations

    def _build_report(
        self,
        room_id: int,
        mod_type: Optional[str],
        installed: set[str],
        duplicates: List[str],
        recommendations: List[Dict[str, Any]],
        filtered_reason: str,
        ai_error: Optional[Exception],
    ) -> str:
        mod_type_label = mod_type or "å…¨éƒ¨"
        lines = ["ðŸ§© æ¨¡ç»„æŽ¨èæŠ¥å‘Š", ""]
        lines.append("ðŸ“Š å½“å‰é…ç½®ï¼š")
        lines.append(f"- æˆ¿é—´IDï¼š{room_id}")
        lines.append(f"- å·²å®‰è£…æ¨¡ç»„ï¼š{len(installed)} ä¸ª")
        lines.append(f"- æŽ¨èç±»åž‹ï¼š{mod_type_label}")
        lines.append(f"- {filtered_reason}")

        if duplicates:
            lines.append(f"- âš ï¸ æ£€æµ‹åˆ°é‡å¤æ¡ç›®ï¼š{len(duplicates)} ä¸ª")

        lines.append("")
        lines.append("ðŸŽ¯ æŽ¨èæ¨¡ç»„ï¼ˆTop 5ï¼‰ï¼š")
        for idx, item in enumerate(recommendations, 1):
            mod_id = item.get("mod_id", "æœªçŸ¥")
            name = item.get("name", "æœªçŸ¥æ¨¡ç»„")
            score = item.get("score", "-")
            reason = item.get("reason", "-")
            lines.append(f"\n{idx}. {name}")
            lines.append(f"   ðŸ“ æ¨¡ç»„ID: {mod_id}")
            lines.append(f"   â­ è¯„åˆ†: {score}/10")
            lines.append(f"   ðŸ’¡ ç†ç”±: {reason}")
            lines.append(f"   ðŸ“¦ å®‰è£…: /dst mod add {room_id} Master {mod_id}")

        if ai_error is not None:
            lines.append("")
            if isinstance(ai_error, AIError):
                lines.append(f"âš ï¸ AI æŽ¨èå¤±è´¥ï¼š{format_ai_error(ai_error)}")
            else:
                lines.append(f"âš ï¸ AI æŽ¨èå¤±è´¥ï¼š{ai_error}")

        return "\n".join(lines)

    def _extract_json(self, text: str) -> Any:
        text = text.strip()
        if not text:
            raise ValueError("empty response")

        if text.startswith("{"):
            return json.loads(text)

        start = text.find("```json")
        if start != -1:
            start = text.find("\n", start)
            end = text.find("```", start + 1)
            if start != -1 and end != -1:
                return json.loads(text[start:end].strip())

        brace_start = text.find("{")
        brace_end = text.rfind("}")
        if brace_start != -1 and brace_end != -1 and brace_end > brace_start:
            return json.loads(text[brace_start: brace_end + 1])

        raise ValueError("æ— æ³•æå– JSON")

    def _get_cached(self, cache_key: str, ttl: int) -> Optional[Dict[str, Any]]:
        cached = self._cache.get(cache_key)
        if not cached:
            return None
        timestamp, value = cached
        if time.monotonic() - timestamp > ttl:
            self._cache.pop(cache_key, None)
            return None
        return value

    def _set_cached(self, cache_key: str, value: Dict[str, Any]) -> None:
        self._cache[cache_key] = (time.monotonic(), value)


_DEFAULT_MOD_POOL: Tuple[ModCandidate, ...] = tuple(
    ModCandidate(
        mod_id=f"workshop-{1000000000 + idx}",
        name=f"Popular Mod {idx:02d}",
        mod_type="functional" if idx % 3 == 0 else "decorative" if idx % 3 == 1 else "balance",
        tags=("popular", "stable"),
    )
    for idx in range(1, 51)
)

_CONFLICT_MAP: Dict[str, set[str]] = {
    "workshop-1000000001": {"workshop-1000000002"},
    "workshop-1000000005": {"workshop-1000000010"},
}
